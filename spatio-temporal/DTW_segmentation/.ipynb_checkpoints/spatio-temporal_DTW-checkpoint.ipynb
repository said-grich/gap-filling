{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "916d2ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import copy\n",
    "import numpy as np\n",
    "from dtw_seg import DTWSegmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b24e8955",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../../data/spatail_mask.pkl\"\n",
    "spatail_masks=None\n",
    "# Open the file in read-binary mode\n",
    "with open(file_path, 'rb') as file:\n",
    "    spatail_masks = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "47261fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../../data/temporal_mask.pkl\"\n",
    "temporal_masks=None\n",
    "# Open the file in read-binary mode\n",
    "with open(file_path, 'rb') as file:\n",
    "    temporal_masks = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "03fe19c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the Spatail Circle Gap\n",
    "circle_gap__spatail=spatail_masks[\"circle\"]\n",
    "separated_gap_spatail=spatail_masks[\"separated\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e525830b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempral_seprated_masks=temporal_masks['separated']\n",
    "tempral_sequential_masks=temporal_masks['sequential']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3d04d885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the Spatail Circle Gap\n",
    "directory_SENTINEL=r\"../../../Images_Zone/Images_Zone/\"\n",
    "mask_30=tempral_seprated_masks[3]\n",
    "bands=[\"B2\",\"B3\",\"B4\",\"B8\",\"B11\",\"B12\"]\n",
    "cas_types=[\"spatail\",\"temporal\"]\n",
    "gap_size_temp=[\"10%\",\"20%\",\"30%\",\"40%\",\"50%\"]\n",
    "spatail_gaps_types=[\"circle\",\"separated\"]\n",
    "temporal_types=[\"sequential\",\"separated\"]\n",
    "for band_2 in bands:\n",
    "    for cas in cas_types:\n",
    "        stack_images_bands[band_2][cas]={}\n",
    "        for i in range(len(tempral_seprated_masks)):\n",
    "            \n",
    "            # first cas we need to to evalute is the spatail cas\n",
    "            if cas ==\"spatail\":\n",
    "                # set the temporal gape size at 20%\n",
    "                temporal_gap_size=mask_30\n",
    "                for spatail_gap_type in spatail_gaps_types:\n",
    "                    stack_images_bands[band_2][cas][spatail_gap_type]={}\n",
    "                    # in case we have circle spatial gap\n",
    "                    if spatail_gap_type == \"circle\":\n",
    "                        for j in range(len(gap_size_temp)):\n",
    "                            gap_size_tmp=gap_size_temp[j]\n",
    "                            gap_spatail_size_mask=circle_gap__spatail[j]\n",
    "                            dates_list=list(stack_images_bands[band_2][\"ground_truth\"].keys())\n",
    "                            stack_images_bands[band_2][cas][spatail_gap_type][gap_size_tmp]={}\n",
    "                            #apply the temporal Gap based on the Mask\n",
    "                            for k in range(len(temporal_gap_size)):\n",
    "                                tmp_temporal_gap_mask=temporal_gap_size[k]\n",
    "                                ground_truth=copy.deepcopy(stack_images_bands[band_2][\"ground_truth\"][dates_list[k]])\n",
    "                                \n",
    "                                if(tmp_temporal_gap_mask):\n",
    "                                    ground_truth[gap_spatail_size_mask]=np.nan\n",
    "                                    stack_images_bands[band_2][cas][spatail_gap_type][gap_size_tmp][dates_list[k]]=ground_truth\n",
    "                                else:\n",
    "                                    stack_images_bands[band_2][cas][spatail_gap_type][gap_size_tmp][dates_list[k]]=ground_truth\n",
    "\n",
    "                    # in case we have separated spatial gap\n",
    "                    elif spatail_gap_type == \"separated\":\n",
    "                        for j in range(len(gap_size_temp)):\n",
    "                            gap_size_tmp=gap_size_temp[j]\n",
    "                            gap_spatail_size_mask=separated_gap_spatail[j]\n",
    "                            dates_list=list(stack_images_bands[band_2][\"ground_truth\"].keys())\n",
    "                            stack_images_bands[band_2][cas][spatail_gap_type][gap_size_tmp]={}\n",
    "                            #apply the temporal Gap based on the Mask\n",
    "                            for k in range(len(temporal_gap_size)):\n",
    "                                tmp_temporal_gap_mask=temporal_gap_size[k]\n",
    "                                ground_truth=copy.deepcopy(stack_images_bands[band_2][\"ground_truth\"][dates_list[k]])\n",
    "                                \n",
    "                                if(tmp_temporal_gap_mask):\n",
    "                                    ground_truth[gap_spatail_size_mask]=np.nan\n",
    "                                    stack_images_bands[band_2][cas][spatail_gap_type][gap_size_tmp][dates_list[k]]=ground_truth\n",
    "                                else:\n",
    "                                    stack_images_bands[band_2][cas][spatail_gap_type][gap_size_tmp][dates_list[k]]=ground_truth\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# first cas we need to to evalute is the spatail cas\n",
    "            if cas ==\"temporal\":\n",
    "                # set the spatail gape size at 20%\n",
    "                spatail_gap_size=separated_gap_spatail[1]\n",
    "                for temporal_gap_type in temporal_types:\n",
    "                    stack_images_bands[band_2][cas][temporal_gap_type]={}\n",
    "                    # in case we have circle spatial gap\n",
    "                    if temporal_gap_type == \"sequential\":\n",
    "                        for j in range(len(gap_size_temp)):\n",
    "                            gap_size_tmp=gap_size_temp[j]\n",
    "                            gap_temporal_size_mask=tempral_sequential_masks[j]\n",
    "                            dates_list=list(stack_images_bands[band_2][\"ground_truth\"].keys())\n",
    "                            stack_images_bands[band_2][cas][temporal_gap_type][gap_size_tmp]={}\n",
    "                            #apply the temporal Gap based on the Mask\n",
    "                            for k in range(len(temporal_gap_size)):\n",
    "                                tmp_temporal_gap_mask=gap_temporal_size_mask[k]\n",
    "                                ground_truth=copy.deepcopy(stack_images_bands[band_2][\"ground_truth\"][dates_list[k]])\n",
    "                                \n",
    "                                if(tmp_temporal_gap_mask):\n",
    "                                    ground_truth[spatail_gap_size]=np.nan\n",
    "                                    stack_images_bands[band_2][cas][temporal_gap_type][gap_size_tmp][dates_list[k]]=ground_truth\n",
    "                                else:\n",
    "                                    stack_images_bands[band_2][cas][temporal_gap_type][gap_size_tmp][dates_list[k]]=ground_truth\n",
    "\n",
    "                    # in case we have separated spatial gap\n",
    "                    elif temporal_gap_type == \"separated\":\n",
    "                        for j in range(len(gap_size_temp)):\n",
    "                            gap_size_tmp=gap_size_temp[j]\n",
    "                            gap_temporal_size_mask=tempral_seprated_masks[j]\n",
    "                            dates_list=list(stack_images_bands[band_2][\"ground_truth\"].keys())\n",
    "                            stack_images_bands[band_2][cas][temporal_gap_type][gap_size_tmp]={}\n",
    "                            #apply the temporal Gap based on the Mask\n",
    "                            for k in range(len(temporal_gap_size)):\n",
    "                                tmp_temporal_gap_mask=gap_temporal_size_mask[k]\n",
    "                                ground_truth=copy.deepcopy(stack_images_bands[band_2][\"ground_truth\"][dates_list[k]])\n",
    "                                \n",
    "                                if(tmp_temporal_gap_mask):\n",
    "                                    ground_truth[spatail_gap_size]=np.nan\n",
    "                                    stack_images_bands[band_2][cas][temporal_gap_type][gap_size_tmp][dates_list[k]]=ground_truth\n",
    "                                else:\n",
    "                                    stack_images_bands[band_2][cas][temporal_gap_type][gap_size_tmp][dates_list[k]]=ground_truth\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d5b0bad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genrate_dataset(images_dict,band,gap_type,gap_sinario,gap_size):\n",
    "    nan_mask=[]\n",
    "    data_list=[]\n",
    "    for date in stack_images_bands[band][gap_type][gap_sinario][gap_size].keys():\n",
    "        image=stack_images_bands[band][gap_type][gap_sinario][gap_size][date]\n",
    "        nan_mask.append(np.isnan(image).any())\n",
    "        # Set pixels with value 0 to NaN\n",
    "        image = np.where(image == 0, np.nan, image)\n",
    "        data_list.append(image)\n",
    "    return np.array(data_list) , nan_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "33d25ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_dtw=DTWSegmentation(test_ds[0].shape,100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "92d91563",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   0%|          | 0/24 [00:00<?, ?it/s]\n",
      "Image 1 Seeds:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Image 1 Seeds:   1%|          | 1/100 [00:03<06:33,  3.98s/it]\u001b[A\n",
      "Processing Images:   4%|â–         | 1/24 [00:12<04:56, 12.88s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-d597401361db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m                     \u001b[0mimage_seeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseg_dtw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_seeds_from_edges_time_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_time_series\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                         \u001b[0mregions_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mband\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgap_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgap_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg_dtw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_segmentation_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnan_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_seeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthreeshoulds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gap_filling/spatio-temporal/DTW_segmentation/dtw_seg.py\u001b[0m in \u001b[0;36mrun_segmentation_process\u001b[0;34m(self, image_series, nan_mask, seeds_per_image, thresholds)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mseeds_of_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseeds_per_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseeds_of_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Image {image_index} Seeds\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrow_region\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_series\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m                     \u001b[0mimage_regions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gap_filling/spatio-temporal/DTW_segmentation/dtw_seg.py\u001b[0m in \u001b[0;36mgrow_region\u001b[0;34m(self, image_time_series, seed, threshold)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;31m# Only proceed if the current pixel is not a NaN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_nan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m                 \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_dtw_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_time_series\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0;31m#             print(f\"distances  ---> {distances}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gap_filling/spatio-temporal/DTW_segmentation/dtw_seg.py\u001b[0m in \u001b[0;36mcompute_dtw_distances\u001b[0;34m(self, image_time_series, seed, neighbors)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mneighbor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneighbors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mneighbor_time_series\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_time_series\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_time_series\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbor_time_series\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0mdistances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneighbor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/dtaidistance/dtw.py\u001b[0m in \u001b[0;36mdistance\u001b[0;34m(s1, s2, window, max_dist, max_step, max_length_diff, penalty, psi, use_c, use_pruning, only_ub, inner_dist)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mskip\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             dtw[i1 * length + j + 1 - skip] = d + min(dtw[i0 * length + j - skipp],\n\u001b[0;32m--> 313\u001b[0;31m                                                       \u001b[0mdtw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mskipp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m                                                       dtw[i1 * length + j - skip] + penalty)\n\u001b[1;32m    315\u001b[0m             \u001b[0;31m# print('({},{}), ({},{}), ({},{})'.format(i0, j - skipp, i0, j + 1 - skipp, i1, j - skip))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "regions_result={}\n",
    "gap_size_list=[\"10%\",\"20%\",\"30%\",\"40%\",\"50%\"]\n",
    "bands=[\"B2\",\"B3\",\"B4\",\"B8\",\"B11\",\"B12\"]\n",
    "gap_types=['spatail', 'temporal']\n",
    "gap_sinarios_list=['circle', 'separated', 'sequential', 'separated']\n",
    "for band in bands:\n",
    "    regions_result[band]={}\n",
    "    for gap_type in gap_types:\n",
    "        regions_result[band][gap_type]={}\n",
    "        for type_ in gap_sinarios_list:\n",
    "                regions_result[band][gap_type][type_]={}\n",
    "                for gap_index , gap_size  in enumerate(gap_size_list):\n",
    "                    regions_result[band][gap_type][type_][gap_size]=[]\n",
    "                    image_time_series,nan_mask=genrate_dataset(stack_images_bands,band,gap_type,type_,gap_size)\n",
    "                    threeshoulds=seg_dtw.calculate_similarity_threshold_mean(test_ds)\n",
    "                    image_seeds=seg_dtw.select_seeds_from_edges_time_series(test_ds,100,10)\n",
    "                    for image in image_time_series:\n",
    "                        regions_result[band][gap_type][type_][gap_size].append(seg_dtw.run_segmentation_process(test_ds,nan_mask,image_seeds,threeshoulds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b9ac7754",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=\"./output/segmentation_result.pkl\"\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(regions_result, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
